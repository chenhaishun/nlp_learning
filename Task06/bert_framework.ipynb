{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "a62e6132-cb67-4edd-84be-fc3142c1b5a6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "class GetInit:\n",
    "    def __init__(self, data_root):\n",
    "        print(\"GetInit Start!\")\n",
    "        self.data_root = data_root\n",
    "        self.x_train, self.y_train, self.x_test,self.x_train_feature,self.x_test_feature = self.get_pandas()\n",
    "        print(\"GetInit End!\")\n",
    "\n",
    "    def get_pandas(self):\n",
    "        train = pd.read_csv(self.data_root[\"train_path\"])\n",
    "        test = pd.read_csv(self.data_root[\"test_path\"])\n",
    "        \n",
    "        x_train = train.text.str.replace(\"900\",\"[SEP]\").replace(\"3750\",\"[SEP]\").values\n",
    "        y_train = train.label.values\n",
    "        x_test = test.text.str.replace(\"900\",\"[SEP]\").replace(\"3750\",\"[SEP]\").values\n",
    "        \n",
    "        train[\"length\"]=train.text.apply(lambda x:len(x.split(\" \")))\n",
    "        test[\"length\"]=test.text.apply(lambda x:len(x.split(\" \")))\n",
    "\n",
    "        train[\"length\"]=np.log10(train[\"length\"])/np.log10(train[\"length\"].max())\n",
    "        test[\"length\"]=np.log10(test[\"length\"])/np.log10(test[\"length\"].max())\n",
    "        \n",
    "        train[\"sentence_length\"]=train.text.apply(lambda x:len(re.split(\" 3750 | 900 \",x)))\n",
    "        test[\"sentence_length\"]=test.text.apply(lambda x:len(re.split(\" 3750 | 900 \",x)))\n",
    "\n",
    "        train[\"sentence_length\"]=np.log10(train[\"sentence_length\"])/np.log10(train[\"sentence_length\"].max())\n",
    "        test[\"sentence_length\"]=np.log10(test[\"sentence_length\"])/np.log10(test[\"sentence_length\"].max())\n",
    "        \n",
    "        x_train_feature=train[[\"length\",\"sentence_length\"]].values\n",
    "        x_test_feature=test[[\"length\",\"sentence_length\"]].values\n",
    "        \n",
    "        \n",
    "        del train\n",
    "        del test\n",
    "        return x_train, y_train, x_test,x_train_feature,x_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "a9332a99-d2d2-482d-9a9e-6ed1aade025f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetInit Start!\n",
      "GetInit End!\n"
     ]
    }
   ],
   "source": [
    "data_root = {\n",
    "    \"train_path\": '../../data/train_sample.csv',\n",
    "    \"test_path\": \"../../data/test_a.csv\",\n",
    "    \"sub_path\": \"../../data/test_a_sample_submit.csv\",\n",
    "    \"w2v_path\": \"../../data/word2vec.bin\"\n",
    "}\n",
    "config = GetInit(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "7b14d59c-6185-43d1-8744-6cf29362f9fe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, bert_path, corpus, feature, corpus_label=None, max_length=256, with_label=False):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.corpus = corpus\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "        self.with_label = with_label\n",
    "        self.max_length = max_length\n",
    "        self.feature = feature\n",
    "        \n",
    "        if self.with_label:\n",
    "            self.corpus_label = torch.tensor(corpus_label)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "                            self.corpus[item],           # 输入文本\n",
    "                            add_special_tokens = True,    # 添加 '[CLS]' 和 '[SEP]'\n",
    "                            max_length = self.max_length,           # 填充 & 截断长度\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,  \n",
    "                            return_tensors = 'pt', \n",
    "                            truncation=True\n",
    "                       )\n",
    "        if self.with_label:\n",
    "            return encoded_dict['input_ids'].squeeze(0),encoded_dict['attention_mask'].squeeze(0),torch.FloatTensor(self.feature[item]),self.corpus_label[item]\n",
    "        else:\n",
    "            return encoded_dict['input_ids'].squeeze(0),encoded_dict['attention_mask'].squeeze(0),torch.FloatTensor(self.feature[item])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "fb5f4d23-8dd8-4833-94eb-007f508e389b"
   },
   "outputs": [],
   "source": [
    "bert_path ='./bert-mini/'\n",
    "train_dataset = MyDataset(bert_path,\n",
    "                          corpus=config.x_train,\n",
    "                          feature=config.x_train_feature,\n",
    "                          corpus_label=config.y_train,\n",
    "                          with_label=True)\n",
    "test_dataset = MyDataset(bert_path,\n",
    "                         corpus=config.x_test,\n",
    "                         feature=config.x_test_feature,\n",
    "                         with_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "919cee81-2bf9-43a6-9259-c139599d7a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "3b08cdf8-71a4-40f5-b9b3-da60bb3c1958"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class GetLoader:\n",
    "    def __init__(self, train_dataset, test_dataset, split_ratio=0.9):\n",
    "        self.ratio = split_ratio\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.train_dataset, self.valid_dataset = self.split()\n",
    "\n",
    "        self.train_loader, self.valid_loader, self.test_loader = None,None,None\n",
    "        self.get_iter()\n",
    "        print(\"GetLoader End\")\n",
    "\n",
    "    def split(self):\n",
    "        train_size = int(self.ratio * len(self.train_dataset))\n",
    "        valid_size = len(self.train_dataset) - train_size\n",
    "        train_dataset, valid_dataset = torch.utils.data.random_split(self.train_dataset, [train_size, valid_size])\n",
    "        return train_dataset, valid_dataset\n",
    "\n",
    "    def get_iter(self):\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=16,shuffle=True)\n",
    "        self.valid_loader = DataLoader(self.valid_dataset, batch_size=64)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "uuid": "3eebeae8-8010-4979-bf3d-1570545a949b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetLoader End\n"
     ]
    }
   ],
   "source": [
    "loader = GetLoader(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "uuid": "4df62f37-9cac-47c5-b945-462e1723c07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256])\n",
      "torch.Size([64, 256])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([16, 256])\n",
      "torch.Size([16, 256])\n",
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, mask,feature) in enumerate(iter(loader.test_loader)):\n",
    "    print(data.shape)\n",
    "    print(mask.shape)\n",
    "    print(feature.shape)\n",
    "    break\n",
    "    \n",
    "for batch_idx, (data, mask,feature,label) in enumerate(iter(loader.train_loader)):\n",
    "    print(data.shape)\n",
    "    print(mask.shape)\n",
    "    print(feature.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "e131a0d9-414d-424c-a609-d79afd703fcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 500, 50000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader.train_loader.dataset),len(loader.valid_loader.dataset),len(loader.test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "uuid": "8802a59e-2c23-405f-ae03-cd14c7d70df7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertModel\n",
    "\n",
    "class Bert(nn.Module):\n",
    "    def __init__(self, bert_path, hidden_size=128, output_size=14, dropout=0.5):\n",
    "        super(Bert, self).__init__()\n",
    "        self.bert =BertModel.from_pretrained(\n",
    "                            bert_path,\n",
    "                            num_labels = 14, \n",
    "                            output_attentions = False, # 模型是否返回 attentions weights.\n",
    "                            output_hidden_states = False, # 模型是否返回所有隐层状态.\n",
    "                        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(258, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, data, mask,feature):\n",
    "        _ ,out=self.bert(data, token_type_ids=None, attention_mask=mask)\n",
    "        out=torch.cat((out,feature),dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        return F.log_softmax(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "uuid": "555e6a76-920a-4f72-9e46-316ef2d005d8"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "uuid": "f7bcb472-301f-42c8-879a-f0c3d7c977b8"
   },
   "outputs": [],
   "source": [
    "# 建立model\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "model=Bert(bert_path)\n",
    "model.cuda()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "epochs = 2\n",
    "total_steps = len(loader.train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(opt, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "uuid": "415ba2b5-a607-4bb9-8af1-58b3739abf0c"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "class TrainFunc:\n",
    "    def __init__(self, model, criterion, opt, schedule, train_iter=None, valid_iter=None, test_iter=None):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        self.schedule = schedule\n",
    "        self.best_model = model\n",
    "        self.best_score = 0\n",
    "        self.train_iter = train_iter\n",
    "        self.valid_iter = valid_iter\n",
    "        self.test_iter = test_iter\n",
    "        self.training_stats = []\n",
    "\n",
    "    def train(self, epoch):\n",
    "\n",
    "        total_t0 = time.time()\n",
    "\n",
    "        for epoch_i in range(0, epoch):\n",
    "            print(\" \")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epoch))\n",
    "            print('Training...')\n",
    "            t0 = time.time()\n",
    "            total_train_loss = 0\n",
    "            self.model.train()\n",
    "            train_acc = 0\n",
    "            # 训练集小批量迭代\n",
    "            for step, (data, mask, feature, label) in enumerate(iter(self.train_iter)):\n",
    "                batch_size = data.shape[0]\n",
    "                data = data.cuda()\n",
    "                mask = mask.cuda()\n",
    "                feature = feature.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "                self.opt.zero_grad()\n",
    "                output = self.model(data, mask, feature)\n",
    "                loss = self.criterion(output, label)\n",
    "                loss.backward()\n",
    "                total_train_loss += loss.item()\n",
    "                train_acc += (output.argmax(1) == label).sum().item()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                self.opt.step()\n",
    "                self.schedule.step()\n",
    "                if step % int(80 * (8 / batch_size)) == 0:\n",
    "                    elapsed = format_time(time.time() - t0)\n",
    "                    print('  Batch {:>5,}  of  {:>5,}.  Loss:{:<20,}   Elapsed: {:}.'.format(step,\n",
    "                                                                                              len(self.train_iter),\n",
    "                                                                                              loss.item(), elapsed))\n",
    "            # 平均训练误差\n",
    "            avg_train_loss = total_train_loss / len(self.train_iter)\n",
    "            # 单次 epoch 的训练时长\n",
    "            training_time = format_time(time.time() - t0)\n",
    "            print(\"\")\n",
    "            print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
    "            print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "            print(\"  Training acc: {0:.4f}\".format(train_acc / len(self.train_iter.dataset) * 100))\n",
    "            score, avg_val_loss, avg_val_accuracy, validation_time = self.valid_func()\n",
    "            if score > self.best_score:\n",
    "                self.best_score = score\n",
    "                self.best_model = deepcopy(self.model)\n",
    "                print(\"  Now_best:{:.4f}\".format(self.best_score))\n",
    "            #         scheduler.step()\n",
    "            self.training_stats.append(\n",
    "                {\n",
    "                    'epoch': epoch_i + 1,\n",
    "                    'Training Loss': avg_train_loss,\n",
    "                    'Valid. Loss': avg_val_loss,\n",
    "                    'Valid. Acc.': avg_val_accuracy,\n",
    "                    'Training Time': training_time,\n",
    "                    'Validation Time': validation_time\n",
    "                }\n",
    "            )\n",
    "        print(\"\")\n",
    "        print(\"Training complete!\")\n",
    "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "        return self.best_model\n",
    "\n",
    "    def valid_func(self):\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        t0 = time.time()\n",
    "        self.model.eval()\n",
    "        valid_acc = 0\n",
    "        valid_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        ans_box = []\n",
    "        label_box = []\n",
    "        for batch_idx, (data, mask, feature, label) in enumerate(iter(self.valid_iter)):\n",
    "            batch_size = data.shape[0]\n",
    "            data = data.cuda()\n",
    "            mask = mask.cuda()\n",
    "            feature = feature.cuda()\n",
    "            label=label.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model(data, mask, feature)\n",
    "                loss = self.criterion(output, label)\n",
    "            pred = output.argmax(1)\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += (pred == label).sum().item()\n",
    "\n",
    "            ans_box.extend(pred.cpu().tolist())\n",
    "            label_box.extend(label.cpu().tolist())\n",
    "        score1 = f1_score(ans_box, label_box, average='macro')\n",
    "        score2 = f1_score(ans_box, label_box, average='micro')\n",
    "\n",
    "        avg_val_accuracy = valid_acc / len(self.valid_iter.dataset) * 100\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "        avg_val_loss = valid_loss / len(self.valid_iter)\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "        print(\"  Micro score: {:}\".format(score2))\n",
    "        print(\"  Macro score: {:}\".format(score1))\n",
    "        # 记录本次 epoch 的所有统计信息\n",
    "\n",
    "        return score1, avg_val_loss, avg_val_accuracy, validation_time\n",
    "\n",
    "    def predict(self):\n",
    "        self.best_model.eval()\n",
    "        t0 = time.time()\n",
    "        ans_box = []\n",
    "        with torch.no_grad():\n",
    "            for step, (data, mask, feature) in enumerate(iter(self.test_iter)):\n",
    "                if step % int(40) == 0:\n",
    "                    elapsed = format_time(time.time() - t0)\n",
    "                    print('  Batch {:>5,}  of  {:>5,}.  Elapsed: {:}.'.format(step,len(self.test_iter),elapsed))\n",
    "                data = data.cuda()\n",
    "                mask =mask.cuda()\n",
    "                feature=feature.cuda()\n",
    "                output = self.best_model(data, mask, feature)\n",
    "                pred = output.argmax(1)\n",
    "                ans_box.extend(pred.cpu().tolist())\n",
    "        return ans_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "uuid": "b4c1074c-50bf-4675-89d9-02dec52bc47f"
   },
   "outputs": [],
   "source": [
    "mytrain = TrainFunc(model, criterion, opt, scheduler, loader.train_loader, loader.valid_loader, loader.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "uuid": "f260081e-f606-4aa1-a252-ea3aed400b24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch     0  of    282.  Loss:2.656054973602295      Elapsed: 0:00:01.\n",
      "  Batch    40  of    282.  Loss:2.541191339492798      Elapsed: 0:00:12.\n",
      "  Batch    80  of    282.  Loss:2.5553131103515625     Elapsed: 0:00:25.\n",
      "  Batch   120  of    282.  Loss:2.4860754013061523     Elapsed: 0:00:37.\n",
      "  Batch   160  of    282.  Loss:2.552767515182495      Elapsed: 0:00:49.\n",
      "  Batch   200  of    282.  Loss:2.373124122619629      Elapsed: 0:01:01.\n",
      "  Batch   240  of    282.  Loss:2.065138816833496      Elapsed: 0:01:12.\n",
      "  Batch   280  of    282.  Loss:1.9945234060287476     Elapsed: 0:01:24.\n",
      "\n",
      "  Average training loss: 2.3385\n",
      "  Training epcoh took: 0:01:24\n",
      "  Training acc: 36.3111\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 56.20\n",
      "  Validation Loss: 2.04\n",
      "  Validation took: 0:00:07\n",
      "  Micro score: 0.562\n",
      "  Macro score: 0.22222269134241027\n",
      "  Now_best:0.2222\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:01:31 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "best_model= mytrain.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "uuid": "865e21dc-e710-4900-b27a-e5207cbc1eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch     0  of    782.  Elapsed: 0:00:01.\n",
      "  Batch    80  of    782.  Elapsed: 0:01:19.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-0ba26179720a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-240-d2ed1e56caa1>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mans_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-7a4028e0222c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     23\u001b[0m                             \u001b[0mreturn_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                             \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                        )\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     (\n\u001b[1;32m    357\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                     )\n\u001b[1;32m    360\u001b[0m                 )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     (\n\u001b[1;32m    357\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                     )\n\u001b[1;32m    360\u001b[0m                 )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_split_on_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m_run_split_on_punc\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ans=mytrain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "4fbfe82e-7baf-4949-a970-8115f83df470"
   },
   "outputs": [],
   "source": [
    "ans[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
