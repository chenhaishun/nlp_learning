{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "a3b22948-10cf-4998-aad4-6932a6c4a903"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from GetLoader import GetLoader\n",
    "from ModelEmbedding import ModelEmbedding\n",
    "from MyDataset import MyDataset\n",
    "from GetInit import GetInit\n",
    "from TrainFunc import TrainFunc\n",
    "from TextCNN import TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "d55eef1a-84e6-4b54-a6a3-d523bcce900b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetInit Start!\n",
      "GetInit End!\n",
      "ModelEmbedding End!\n"
     ]
    }
   ],
   "source": [
    "data_root = {\n",
    "    \"train_path\": '../../data/train_torch.csv',\n",
    "    \"test_path\": \"../../data/test_a.csv\",\n",
    "    \"sub_path\": \"../../data/test_a_sample_submit.csv\",\n",
    "    \"w2v_path\": \"../../data/word2vec.bin\"\n",
    "}\n",
    "config = GetInit(data_root)\n",
    "model_embedding = ModelEmbedding(data_root[\"w2v_path\"])\n",
    "\n",
    "train_dataset = MyDataset(model_embedding,\n",
    "                          corpus=config.x_train,\n",
    "                          corpus_label=config.y_train,\n",
    "                          with_label=True)\n",
    "test_dataset = MyDataset(model_embedding,\n",
    "                         corpus=config.x_test,\n",
    "                         with_label=False)\n",
    "loader = GetLoader(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "4ba37589-f538-47dc-868c-ef2567bc8385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetLoader End\n"
     ]
    }
   ],
   "source": [
    "# 建立model\n",
    "model = TextCNN(vocab_size=model_embedding.dict_length, embedding_dim=300, output_size=14)\n",
    "model.init_weights(model_embedding.embedding, is_static=False)\n",
    "model = model.cuda()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# 开始训练\n",
    "mytrain = TrainFunc(model, criterion, opt, loader.train_loader, loader.valid_loader, loader.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "uuid": "cc5419d0-6902-4b45-9b17-50e129bf5070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/180000 (0%)]\tLoss: 2.728758\n",
      "Train Epoch: 1 [12800/180000 (7%)]\tLoss: 1.678077\n",
      "Train Epoch: 1 [25600/180000 (14%)]\tLoss: 1.124747\n",
      "Train Epoch: 1 [38400/180000 (21%)]\tLoss: 0.710934\n",
      "Train Epoch: 1 [51200/180000 (28%)]\tLoss: 0.556901\n",
      "Train Epoch: 1 [64000/180000 (36%)]\tLoss: 0.673313\n",
      "Train Epoch: 1 [76800/180000 (43%)]\tLoss: 0.571208\n",
      "Train Epoch: 1 [89600/180000 (50%)]\tLoss: 0.396836\n",
      "Train Epoch: 1 [102400/180000 (57%)]\tLoss: 0.322723\n",
      "Train Epoch: 1 [115200/180000 (64%)]\tLoss: 0.530926\n",
      "Train Epoch: 1 [128000/180000 (71%)]\tLoss: 0.397607\n",
      "Train Epoch: 1 [140800/180000 (78%)]\tLoss: 0.372316\n",
      "Train Epoch: 1 [153600/180000 (85%)]\tLoss: 0.415599\n",
      "Train Epoch: 1 [166400/180000 (92%)]\tLoss: 0.357137\n",
      "Train Epoch: 1 [179200/180000 (100%)]\tLoss: 0.208100\n",
      "\tLoss: 0.6457(train)\t|\tAcc: 81.9%(train)\n",
      "\tLoss: 0.3172(valid)\t|\tAcc: 90.2%(valid)\n",
      "\tMicro: 0.9022(valid)\t|\tMacro: 0.8612(valid)\n",
      "Now_best:0.8612\n",
      "Train Epoch: 2 [0/180000 (0%)]\tLoss: 0.422291\n",
      "Train Epoch: 2 [12800/180000 (7%)]\tLoss: 0.182500\n",
      "Train Epoch: 2 [25600/180000 (14%)]\tLoss: 0.298516\n",
      "Train Epoch: 2 [38400/180000 (21%)]\tLoss: 0.279373\n",
      "Train Epoch: 2 [51200/180000 (28%)]\tLoss: 0.177308\n",
      "Train Epoch: 2 [64000/180000 (36%)]\tLoss: 0.366265\n",
      "Train Epoch: 2 [76800/180000 (43%)]\tLoss: 0.370450\n",
      "Train Epoch: 2 [89600/180000 (50%)]\tLoss: 0.206220\n",
      "Train Epoch: 2 [102400/180000 (57%)]\tLoss: 0.206798\n",
      "Train Epoch: 2 [115200/180000 (64%)]\tLoss: 0.371440\n",
      "Train Epoch: 2 [128000/180000 (71%)]\tLoss: 0.322034\n",
      "Train Epoch: 2 [140800/180000 (78%)]\tLoss: 0.292833\n",
      "Train Epoch: 2 [153600/180000 (85%)]\tLoss: 0.355286\n",
      "Train Epoch: 2 [166400/180000 (92%)]\tLoss: 0.324651\n",
      "Train Epoch: 2 [179200/180000 (100%)]\tLoss: 0.137368\n",
      "\tLoss: 0.2746(train)\t|\tAcc: 91.7%(train)\n",
      "\tLoss: 0.2530(valid)\t|\tAcc: 92.1%(valid)\n",
      "\tMicro: 0.9208(valid)\t|\tMacro: 0.8995(valid)\n",
      "Now_best:0.8995\n",
      "Train Epoch: 3 [0/180000 (0%)]\tLoss: 0.371351\n",
      "Train Epoch: 3 [12800/180000 (7%)]\tLoss: 0.123109\n",
      "Train Epoch: 3 [25600/180000 (14%)]\tLoss: 0.196943\n",
      "Train Epoch: 3 [38400/180000 (21%)]\tLoss: 0.259742\n",
      "Train Epoch: 3 [51200/180000 (28%)]\tLoss: 0.124858\n",
      "Train Epoch: 3 [64000/180000 (36%)]\tLoss: 0.322156\n",
      "Train Epoch: 3 [76800/180000 (43%)]\tLoss: 0.297358\n",
      "Train Epoch: 3 [89600/180000 (50%)]\tLoss: 0.136556\n",
      "Train Epoch: 3 [102400/180000 (57%)]\tLoss: 0.172307\n",
      "Train Epoch: 3 [115200/180000 (64%)]\tLoss: 0.286456\n",
      "Train Epoch: 3 [128000/180000 (71%)]\tLoss: 0.309868\n",
      "Train Epoch: 3 [140800/180000 (78%)]\tLoss: 0.234882\n",
      "Train Epoch: 3 [153600/180000 (85%)]\tLoss: 0.323615\n",
      "Train Epoch: 3 [166400/180000 (92%)]\tLoss: 0.300327\n",
      "Train Epoch: 3 [179200/180000 (100%)]\tLoss: 0.104070\n",
      "\tLoss: 0.2241(train)\t|\tAcc: 93.1%(train)\n",
      "\tLoss: 0.2261(valid)\t|\tAcc: 92.9%(valid)\n",
      "\tMicro: 0.9293(valid)\t|\tMacro: 0.9117(valid)\n",
      "Now_best:0.9117\n",
      "Train Epoch: 4 [0/180000 (0%)]\tLoss: 0.324326\n",
      "Train Epoch: 4 [12800/180000 (7%)]\tLoss: 0.094082\n",
      "Train Epoch: 4 [25600/180000 (14%)]\tLoss: 0.145703\n",
      "Train Epoch: 4 [38400/180000 (21%)]\tLoss: 0.243749\n",
      "Train Epoch: 4 [51200/180000 (28%)]\tLoss: 0.095407\n",
      "Train Epoch: 4 [64000/180000 (36%)]\tLoss: 0.297715\n",
      "Train Epoch: 4 [76800/180000 (43%)]\tLoss: 0.260398\n",
      "Train Epoch: 4 [89600/180000 (50%)]\tLoss: 0.097770\n",
      "Train Epoch: 4 [102400/180000 (57%)]\tLoss: 0.151129\n",
      "Train Epoch: 4 [115200/180000 (64%)]\tLoss: 0.224298\n",
      "Train Epoch: 4 [128000/180000 (71%)]\tLoss: 0.308096\n",
      "Train Epoch: 4 [140800/180000 (78%)]\tLoss: 0.197654\n",
      "Train Epoch: 4 [153600/180000 (85%)]\tLoss: 0.294330\n",
      "Train Epoch: 4 [166400/180000 (92%)]\tLoss: 0.274987\n",
      "Train Epoch: 4 [179200/180000 (100%)]\tLoss: 0.084609\n",
      "\tLoss: 0.1947(train)\t|\tAcc: 94.0%(train)\n",
      "\tLoss: 0.2102(valid)\t|\tAcc: 93.3%(valid)\n",
      "\tMicro: 0.9335(valid)\t|\tMacro: 0.9180(valid)\n",
      "Now_best:0.9180\n",
      "Train Epoch: 5 [0/180000 (0%)]\tLoss: 0.287585\n",
      "Train Epoch: 5 [12800/180000 (7%)]\tLoss: 0.079278\n",
      "Train Epoch: 5 [25600/180000 (14%)]\tLoss: 0.115266\n",
      "Train Epoch: 5 [38400/180000 (21%)]\tLoss: 0.230338\n",
      "Train Epoch: 5 [51200/180000 (28%)]\tLoss: 0.081827\n",
      "Train Epoch: 5 [64000/180000 (36%)]\tLoss: 0.281404\n",
      "Train Epoch: 5 [76800/180000 (43%)]\tLoss: 0.238873\n",
      "Train Epoch: 5 [89600/180000 (50%)]\tLoss: 0.075863\n",
      "Train Epoch: 5 [102400/180000 (57%)]\tLoss: 0.134978\n",
      "Train Epoch: 5 [115200/180000 (64%)]\tLoss: 0.185280\n",
      "Train Epoch: 5 [128000/180000 (71%)]\tLoss: 0.301913\n",
      "Train Epoch: 5 [140800/180000 (78%)]\tLoss: 0.174463\n",
      "Train Epoch: 5 [153600/180000 (85%)]\tLoss: 0.273021\n",
      "Train Epoch: 5 [166400/180000 (92%)]\tLoss: 0.252047\n",
      "Train Epoch: 5 [179200/180000 (100%)]\tLoss: 0.069135\n",
      "\tLoss: 0.1735(train)\t|\tAcc: 94.7%(train)\n",
      "\tLoss: 0.1994(valid)\t|\tAcc: 93.6%(valid)\n",
      "\tMicro: 0.9364(valid)\t|\tMacro: 0.9232(valid)\n",
      "Now_best:0.9232\n",
      "Train Epoch: 6 [0/180000 (0%)]\tLoss: 0.253194\n",
      "Train Epoch: 6 [12800/180000 (7%)]\tLoss: 0.070987\n",
      "Train Epoch: 6 [25600/180000 (14%)]\tLoss: 0.097257\n",
      "Train Epoch: 6 [38400/180000 (21%)]\tLoss: 0.217682\n",
      "Train Epoch: 6 [51200/180000 (28%)]\tLoss: 0.072720\n",
      "Train Epoch: 6 [64000/180000 (36%)]\tLoss: 0.266417\n",
      "Train Epoch: 6 [76800/180000 (43%)]\tLoss: 0.220865\n",
      "Train Epoch: 6 [89600/180000 (50%)]\tLoss: 0.063222\n",
      "Train Epoch: 6 [102400/180000 (57%)]\tLoss: 0.122081\n",
      "Train Epoch: 6 [115200/180000 (64%)]\tLoss: 0.160613\n",
      "Train Epoch: 6 [128000/180000 (71%)]\tLoss: 0.289300\n",
      "Train Epoch: 6 [140800/180000 (78%)]\tLoss: 0.152552\n",
      "Train Epoch: 6 [153600/180000 (85%)]\tLoss: 0.254198\n",
      "Train Epoch: 6 [166400/180000 (92%)]\tLoss: 0.230931\n",
      "Train Epoch: 6 [179200/180000 (100%)]\tLoss: 0.058058\n",
      "\tLoss: 0.1564(train)\t|\tAcc: 95.2%(train)\n",
      "\tLoss: 0.1917(valid)\t|\tAcc: 93.8%(valid)\n",
      "\tMicro: 0.9380(valid)\t|\tMacro: 0.9266(valid)\n",
      "Now_best:0.9266\n",
      "Train Epoch: 7 [0/180000 (0%)]\tLoss: 0.226500\n",
      "Train Epoch: 7 [12800/180000 (7%)]\tLoss: 0.064282\n",
      "Train Epoch: 7 [25600/180000 (14%)]\tLoss: 0.083389\n",
      "Train Epoch: 7 [38400/180000 (21%)]\tLoss: 0.204761\n",
      "Train Epoch: 7 [51200/180000 (28%)]\tLoss: 0.068229\n",
      "Train Epoch: 7 [64000/180000 (36%)]\tLoss: 0.254316\n",
      "Train Epoch: 7 [76800/180000 (43%)]\tLoss: 0.206035\n",
      "Train Epoch: 7 [89600/180000 (50%)]\tLoss: 0.054190\n",
      "Train Epoch: 7 [102400/180000 (57%)]\tLoss: 0.109643\n",
      "Train Epoch: 7 [115200/180000 (64%)]\tLoss: 0.142634\n",
      "Train Epoch: 7 [128000/180000 (71%)]\tLoss: 0.274814\n",
      "Train Epoch: 7 [140800/180000 (78%)]\tLoss: 0.134308\n",
      "Train Epoch: 7 [153600/180000 (85%)]\tLoss: 0.235670\n",
      "Train Epoch: 7 [166400/180000 (92%)]\tLoss: 0.212178\n",
      "Train Epoch: 7 [179200/180000 (100%)]\tLoss: 0.050708\n",
      "\tLoss: 0.1418(train)\t|\tAcc: 95.6%(train)\n",
      "\tLoss: 0.1860(valid)\t|\tAcc: 94.0%(valid)\n",
      "\tMicro: 0.9396(valid)\t|\tMacro: 0.9295(valid)\n",
      "Now_best:0.9295\n",
      "Train Epoch: 8 [0/180000 (0%)]\tLoss: 0.207207\n",
      "Train Epoch: 8 [12800/180000 (7%)]\tLoss: 0.057871\n",
      "Train Epoch: 8 [25600/180000 (14%)]\tLoss: 0.071042\n",
      "Train Epoch: 8 [38400/180000 (21%)]\tLoss: 0.190972\n",
      "Train Epoch: 8 [51200/180000 (28%)]\tLoss: 0.064342\n",
      "Train Epoch: 8 [64000/180000 (36%)]\tLoss: 0.240921\n",
      "Train Epoch: 8 [76800/180000 (43%)]\tLoss: 0.191975\n",
      "Train Epoch: 8 [89600/180000 (50%)]\tLoss: 0.047038\n",
      "Train Epoch: 8 [102400/180000 (57%)]\tLoss: 0.099091\n",
      "Train Epoch: 8 [115200/180000 (64%)]\tLoss: 0.128049\n",
      "Train Epoch: 8 [128000/180000 (71%)]\tLoss: 0.260234\n",
      "Train Epoch: 8 [140800/180000 (78%)]\tLoss: 0.117330\n",
      "Train Epoch: 8 [153600/180000 (85%)]\tLoss: 0.217029\n",
      "Train Epoch: 8 [166400/180000 (92%)]\tLoss: 0.192697\n",
      "Train Epoch: 8 [179200/180000 (100%)]\tLoss: 0.044401\n",
      "\tLoss: 0.1289(train)\t|\tAcc: 96.0%(train)\n",
      "\tLoss: 0.1819(valid)\t|\tAcc: 94.2%(valid)\n",
      "\tMicro: 0.9417(valid)\t|\tMacro: 0.9321(valid)\n",
      "Now_best:0.9321\n",
      "Train Epoch: 9 [0/180000 (0%)]\tLoss: 0.191939\n",
      "Train Epoch: 9 [12800/180000 (7%)]\tLoss: 0.053318\n",
      "Train Epoch: 9 [25600/180000 (14%)]\tLoss: 0.061459\n",
      "Train Epoch: 9 [38400/180000 (21%)]\tLoss: 0.175641\n",
      "Train Epoch: 9 [51200/180000 (28%)]\tLoss: 0.061178\n",
      "Train Epoch: 9 [64000/180000 (36%)]\tLoss: 0.225888\n",
      "Train Epoch: 9 [76800/180000 (43%)]\tLoss: 0.176582\n",
      "Train Epoch: 9 [89600/180000 (50%)]\tLoss: 0.041756\n",
      "Train Epoch: 9 [102400/180000 (57%)]\tLoss: 0.090648\n",
      "Train Epoch: 9 [115200/180000 (64%)]\tLoss: 0.115832\n",
      "Train Epoch: 9 [128000/180000 (71%)]\tLoss: 0.245907\n",
      "Train Epoch: 9 [140800/180000 (78%)]\tLoss: 0.102262\n",
      "Train Epoch: 9 [153600/180000 (85%)]\tLoss: 0.199442\n",
      "Train Epoch: 9 [166400/180000 (92%)]\tLoss: 0.171221\n",
      "Train Epoch: 9 [179200/180000 (100%)]\tLoss: 0.039588\n",
      "\tLoss: 0.1172(train)\t|\tAcc: 96.4%(train)\n",
      "\tLoss: 0.1788(valid)\t|\tAcc: 94.2%(valid)\n",
      "\tMicro: 0.9425(valid)\t|\tMacro: 0.9320(valid)\n",
      "Train Epoch: 10 [0/180000 (0%)]\tLoss: 0.177218\n",
      "Train Epoch: 10 [12800/180000 (7%)]\tLoss: 0.048940\n",
      "Train Epoch: 10 [25600/180000 (14%)]\tLoss: 0.052792\n",
      "Train Epoch: 10 [38400/180000 (21%)]\tLoss: 0.163435\n",
      "Train Epoch: 10 [51200/180000 (28%)]\tLoss: 0.056932\n",
      "Train Epoch: 10 [64000/180000 (36%)]\tLoss: 0.208241\n",
      "Train Epoch: 10 [76800/180000 (43%)]\tLoss: 0.161535\n",
      "Train Epoch: 10 [89600/180000 (50%)]\tLoss: 0.037891\n",
      "Train Epoch: 10 [102400/180000 (57%)]\tLoss: 0.083080\n",
      "Train Epoch: 10 [115200/180000 (64%)]\tLoss: 0.105342\n",
      "Train Epoch: 10 [128000/180000 (71%)]\tLoss: 0.229612\n",
      "Train Epoch: 10 [140800/180000 (78%)]\tLoss: 0.088981\n",
      "Train Epoch: 10 [153600/180000 (85%)]\tLoss: 0.185962\n",
      "Train Epoch: 10 [166400/180000 (92%)]\tLoss: 0.152940\n",
      "Train Epoch: 10 [179200/180000 (100%)]\tLoss: 0.034688\n",
      "\tLoss: 0.1064(train)\t|\tAcc: 96.8%(train)\n",
      "\tLoss: 0.1766(valid)\t|\tAcc: 94.3%(valid)\n",
      "\tMicro: 0.9427(valid)\t|\tMacro: 0.9326(valid)\n",
      "Now_best:0.9326\n",
      "Train Epoch: 11 [0/180000 (0%)]\tLoss: 0.167870\n",
      "Train Epoch: 11 [12800/180000 (7%)]\tLoss: 0.044217\n",
      "Train Epoch: 11 [25600/180000 (14%)]\tLoss: 0.045328\n",
      "Train Epoch: 11 [38400/180000 (21%)]\tLoss: 0.147953\n",
      "Train Epoch: 11 [51200/180000 (28%)]\tLoss: 0.052048\n",
      "Train Epoch: 11 [64000/180000 (36%)]\tLoss: 0.189836\n",
      "Train Epoch: 11 [76800/180000 (43%)]\tLoss: 0.146535\n",
      "Train Epoch: 11 [89600/180000 (50%)]\tLoss: 0.035746\n",
      "Train Epoch: 11 [102400/180000 (57%)]\tLoss: 0.076478\n",
      "Train Epoch: 11 [115200/180000 (64%)]\tLoss: 0.096330\n",
      "Train Epoch: 11 [128000/180000 (71%)]\tLoss: 0.208521\n",
      "Train Epoch: 11 [140800/180000 (78%)]\tLoss: 0.078712\n",
      "Train Epoch: 11 [153600/180000 (85%)]\tLoss: 0.169959\n",
      "Train Epoch: 11 [166400/180000 (92%)]\tLoss: 0.134937\n",
      "Train Epoch: 11 [179200/180000 (100%)]\tLoss: 0.031048\n",
      "\tLoss: 0.0963(train)\t|\tAcc: 97.2%(train)\n",
      "\tLoss: 0.1754(valid)\t|\tAcc: 94.3%(valid)\n",
      "\tMicro: 0.9432(valid)\t|\tMacro: 0.9330(valid)\n",
      "Now_best:0.9330\n",
      "Train Epoch: 12 [0/180000 (0%)]\tLoss: 0.158077\n",
      "Train Epoch: 12 [12800/180000 (7%)]\tLoss: 0.040266\n",
      "Train Epoch: 12 [25600/180000 (14%)]\tLoss: 0.038815\n",
      "Train Epoch: 12 [38400/180000 (21%)]\tLoss: 0.130343\n",
      "Train Epoch: 12 [51200/180000 (28%)]\tLoss: 0.046847\n",
      "Train Epoch: 12 [64000/180000 (36%)]\tLoss: 0.173295\n",
      "Train Epoch: 12 [76800/180000 (43%)]\tLoss: 0.129946\n",
      "Train Epoch: 12 [89600/180000 (50%)]\tLoss: 0.033167\n",
      "Train Epoch: 12 [102400/180000 (57%)]\tLoss: 0.069335\n",
      "Train Epoch: 12 [115200/180000 (64%)]\tLoss: 0.087625\n",
      "Train Epoch: 12 [128000/180000 (71%)]\tLoss: 0.189277\n",
      "Train Epoch: 12 [140800/180000 (78%)]\tLoss: 0.069651\n",
      "Train Epoch: 12 [153600/180000 (85%)]\tLoss: 0.155110\n",
      "Train Epoch: 12 [166400/180000 (92%)]\tLoss: 0.118211\n",
      "Train Epoch: 12 [179200/180000 (100%)]\tLoss: 0.028081\n",
      "\tLoss: 0.0868(train)\t|\tAcc: 97.5%(train)\n",
      "\tLoss: 0.1747(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9439(valid)\t|\tMacro: 0.9341(valid)\n",
      "Now_best:0.9341\n",
      "Train Epoch: 13 [0/180000 (0%)]\tLoss: 0.147370\n",
      "Train Epoch: 13 [12800/180000 (7%)]\tLoss: 0.036883\n",
      "Train Epoch: 13 [25600/180000 (14%)]\tLoss: 0.032913\n",
      "Train Epoch: 13 [38400/180000 (21%)]\tLoss: 0.115153\n",
      "Train Epoch: 13 [51200/180000 (28%)]\tLoss: 0.042904\n",
      "Train Epoch: 13 [64000/180000 (36%)]\tLoss: 0.156324\n",
      "Train Epoch: 13 [76800/180000 (43%)]\tLoss: 0.114404\n",
      "Train Epoch: 13 [89600/180000 (50%)]\tLoss: 0.030403\n",
      "Train Epoch: 13 [102400/180000 (57%)]\tLoss: 0.063367\n",
      "Train Epoch: 13 [115200/180000 (64%)]\tLoss: 0.079644\n",
      "Train Epoch: 13 [128000/180000 (71%)]\tLoss: 0.170624\n",
      "Train Epoch: 13 [140800/180000 (78%)]\tLoss: 0.061659\n",
      "Train Epoch: 13 [153600/180000 (85%)]\tLoss: 0.141313\n",
      "Train Epoch: 13 [166400/180000 (92%)]\tLoss: 0.101019\n",
      "Train Epoch: 13 [179200/180000 (100%)]\tLoss: 0.025212\n",
      "\tLoss: 0.0779(train)\t|\tAcc: 97.9%(train)\n",
      "\tLoss: 0.1746(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9439(valid)\t|\tMacro: 0.9352(valid)\n",
      "Now_best:0.9352\n",
      "Train Epoch: 14 [0/180000 (0%)]\tLoss: 0.138048\n",
      "Train Epoch: 14 [12800/180000 (7%)]\tLoss: 0.033778\n",
      "Train Epoch: 14 [25600/180000 (14%)]\tLoss: 0.027914\n",
      "Train Epoch: 14 [38400/180000 (21%)]\tLoss: 0.100411\n",
      "Train Epoch: 14 [51200/180000 (28%)]\tLoss: 0.038289\n",
      "Train Epoch: 14 [64000/180000 (36%)]\tLoss: 0.139274\n",
      "Train Epoch: 14 [76800/180000 (43%)]\tLoss: 0.098579\n",
      "Train Epoch: 14 [89600/180000 (50%)]\tLoss: 0.028081\n",
      "Train Epoch: 14 [102400/180000 (57%)]\tLoss: 0.057251\n",
      "Train Epoch: 14 [115200/180000 (64%)]\tLoss: 0.071773\n",
      "Train Epoch: 14 [128000/180000 (71%)]\tLoss: 0.151027\n",
      "Train Epoch: 14 [140800/180000 (78%)]\tLoss: 0.055194\n",
      "Train Epoch: 14 [153600/180000 (85%)]\tLoss: 0.126276\n",
      "Train Epoch: 14 [166400/180000 (92%)]\tLoss: 0.086236\n",
      "Train Epoch: 14 [179200/180000 (100%)]\tLoss: 0.022804\n",
      "\tLoss: 0.0694(train)\t|\tAcc: 98.2%(train)\n",
      "\tLoss: 0.1752(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9440(valid)\t|\tMacro: 0.9353(valid)\n",
      "Now_best:0.9353\n",
      "Train Epoch: 15 [0/180000 (0%)]\tLoss: 0.125646\n",
      "Train Epoch: 15 [12800/180000 (7%)]\tLoss: 0.030681\n",
      "Train Epoch: 15 [25600/180000 (14%)]\tLoss: 0.024573\n",
      "Train Epoch: 15 [38400/180000 (21%)]\tLoss: 0.085478\n",
      "Train Epoch: 15 [51200/180000 (28%)]\tLoss: 0.033777\n",
      "Train Epoch: 15 [64000/180000 (36%)]\tLoss: 0.122822\n",
      "Train Epoch: 15 [76800/180000 (43%)]\tLoss: 0.084416\n",
      "Train Epoch: 15 [89600/180000 (50%)]\tLoss: 0.024852\n",
      "Train Epoch: 15 [102400/180000 (57%)]\tLoss: 0.051688\n",
      "Train Epoch: 15 [115200/180000 (64%)]\tLoss: 0.064444\n",
      "Train Epoch: 15 [128000/180000 (71%)]\tLoss: 0.132672\n",
      "Train Epoch: 15 [140800/180000 (78%)]\tLoss: 0.048754\n",
      "Train Epoch: 15 [153600/180000 (85%)]\tLoss: 0.110446\n",
      "Train Epoch: 15 [166400/180000 (92%)]\tLoss: 0.074388\n",
      "Train Epoch: 15 [179200/180000 (100%)]\tLoss: 0.020416\n",
      "\tLoss: 0.0614(train)\t|\tAcc: 98.5%(train)\n",
      "\tLoss: 0.1762(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9438(valid)\t|\tMacro: 0.9349(valid)\n",
      "Train Epoch: 16 [0/180000 (0%)]\tLoss: 0.112995\n",
      "Train Epoch: 16 [12800/180000 (7%)]\tLoss: 0.027668\n",
      "Train Epoch: 16 [25600/180000 (14%)]\tLoss: 0.021749\n",
      "Train Epoch: 16 [38400/180000 (21%)]\tLoss: 0.072628\n",
      "Train Epoch: 16 [51200/180000 (28%)]\tLoss: 0.030874\n",
      "Train Epoch: 16 [64000/180000 (36%)]\tLoss: 0.107930\n",
      "Train Epoch: 16 [76800/180000 (43%)]\tLoss: 0.070269\n",
      "Train Epoch: 16 [89600/180000 (50%)]\tLoss: 0.022902\n",
      "Train Epoch: 16 [102400/180000 (57%)]\tLoss: 0.045780\n",
      "Train Epoch: 16 [115200/180000 (64%)]\tLoss: 0.055742\n",
      "Train Epoch: 16 [128000/180000 (71%)]\tLoss: 0.115280\n",
      "Train Epoch: 16 [140800/180000 (78%)]\tLoss: 0.042985\n",
      "Train Epoch: 16 [153600/180000 (85%)]\tLoss: 0.097249\n",
      "Train Epoch: 16 [166400/180000 (92%)]\tLoss: 0.063138\n",
      "Train Epoch: 16 [179200/180000 (100%)]\tLoss: 0.018214\n",
      "\tLoss: 0.0540(train)\t|\tAcc: 98.7%(train)\n",
      "\tLoss: 0.1778(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9439(valid)\t|\tMacro: 0.9357(valid)\n",
      "Now_best:0.9357\n",
      "Train Epoch: 17 [0/180000 (0%)]\tLoss: 0.102576\n",
      "Train Epoch: 17 [12800/180000 (7%)]\tLoss: 0.024638\n",
      "Train Epoch: 17 [25600/180000 (14%)]\tLoss: 0.019472\n",
      "Train Epoch: 17 [38400/180000 (21%)]\tLoss: 0.060605\n",
      "Train Epoch: 17 [51200/180000 (28%)]\tLoss: 0.027532\n",
      "Train Epoch: 17 [64000/180000 (36%)]\tLoss: 0.092875\n",
      "Train Epoch: 17 [76800/180000 (43%)]\tLoss: 0.057867\n",
      "Train Epoch: 17 [89600/180000 (50%)]\tLoss: 0.020156\n",
      "Train Epoch: 17 [102400/180000 (57%)]\tLoss: 0.040487\n",
      "Train Epoch: 17 [115200/180000 (64%)]\tLoss: 0.047362\n",
      "Train Epoch: 17 [128000/180000 (71%)]\tLoss: 0.097856\n",
      "Train Epoch: 17 [140800/180000 (78%)]\tLoss: 0.037641\n",
      "Train Epoch: 17 [153600/180000 (85%)]\tLoss: 0.083573\n",
      "Train Epoch: 17 [166400/180000 (92%)]\tLoss: 0.052540\n",
      "Train Epoch: 17 [179200/180000 (100%)]\tLoss: 0.016201\n",
      "\tLoss: 0.0470(train)\t|\tAcc: 99.0%(train)\n",
      "\tLoss: 0.1797(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9439(valid)\t|\tMacro: 0.9359(valid)\n",
      "Now_best:0.9359\n",
      "Train Epoch: 18 [0/180000 (0%)]\tLoss: 0.091943\n",
      "Train Epoch: 18 [12800/180000 (7%)]\tLoss: 0.021949\n",
      "Train Epoch: 18 [25600/180000 (14%)]\tLoss: 0.017019\n",
      "Train Epoch: 18 [38400/180000 (21%)]\tLoss: 0.050609\n",
      "Train Epoch: 18 [51200/180000 (28%)]\tLoss: 0.024761\n",
      "Train Epoch: 18 [64000/180000 (36%)]\tLoss: 0.077466\n",
      "Train Epoch: 18 [76800/180000 (43%)]\tLoss: 0.047011\n",
      "Train Epoch: 18 [89600/180000 (50%)]\tLoss: 0.017487\n",
      "Train Epoch: 18 [102400/180000 (57%)]\tLoss: 0.035008\n",
      "Train Epoch: 18 [115200/180000 (64%)]\tLoss: 0.039373\n",
      "Train Epoch: 18 [128000/180000 (71%)]\tLoss: 0.083324\n",
      "Train Epoch: 18 [140800/180000 (78%)]\tLoss: 0.032405\n",
      "Train Epoch: 18 [153600/180000 (85%)]\tLoss: 0.071722\n",
      "Train Epoch: 18 [166400/180000 (92%)]\tLoss: 0.043642\n",
      "Train Epoch: 18 [179200/180000 (100%)]\tLoss: 0.014292\n",
      "\tLoss: 0.0405(train)\t|\tAcc: 99.2%(train)\n",
      "\tLoss: 0.1821(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9441(valid)\t|\tMacro: 0.9356(valid)\n",
      "Train Epoch: 19 [0/180000 (0%)]\tLoss: 0.081736\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f59308d7bdae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/nas/workspace/jupyter/code/TextCNN/TrainFunc.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = mytrain.train(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "uuid": "cc6ee546-094a-455f-bd10-5165355c31e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/180000 (0%)]\tLoss: 0.058866\n",
      "Train Epoch: 1 [12800/180000 (7%)]\tLoss: 0.022962\n",
      "Train Epoch: 1 [25600/180000 (14%)]\tLoss: 0.015323\n",
      "Train Epoch: 1 [38400/180000 (21%)]\tLoss: 0.041388\n",
      "Train Epoch: 1 [51200/180000 (28%)]\tLoss: 0.021106\n",
      "Train Epoch: 1 [64000/180000 (36%)]\tLoss: 0.066051\n",
      "Train Epoch: 1 [76800/180000 (43%)]\tLoss: 0.038057\n",
      "Train Epoch: 1 [89600/180000 (50%)]\tLoss: 0.014788\n",
      "Train Epoch: 1 [102400/180000 (57%)]\tLoss: 0.029982\n",
      "Train Epoch: 1 [115200/180000 (64%)]\tLoss: 0.031499\n",
      "Train Epoch: 1 [128000/180000 (71%)]\tLoss: 0.068466\n",
      "Train Epoch: 1 [140800/180000 (78%)]\tLoss: 0.029149\n",
      "Train Epoch: 1 [153600/180000 (85%)]\tLoss: 0.062011\n",
      "Train Epoch: 1 [166400/180000 (92%)]\tLoss: 0.035421\n",
      "Train Epoch: 1 [179200/180000 (100%)]\tLoss: 0.012467\n",
      "\tLoss: 0.0342(train)\t|\tAcc: 99.4%(train)\n",
      "\tLoss: 0.1855(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9438(valid)\t|\tMacro: 0.9352(valid)\n",
      "Now_best:0.9352\n",
      "Train Epoch: 2 [0/180000 (0%)]\tLoss: 0.045769\n",
      "Train Epoch: 2 [12800/180000 (7%)]\tLoss: 0.015732\n",
      "Train Epoch: 2 [25600/180000 (14%)]\tLoss: 0.012166\n",
      "Train Epoch: 2 [38400/180000 (21%)]\tLoss: 0.034306\n",
      "Train Epoch: 2 [51200/180000 (28%)]\tLoss: 0.018359\n",
      "Train Epoch: 2 [64000/180000 (36%)]\tLoss: 0.052246\n",
      "Train Epoch: 2 [76800/180000 (43%)]\tLoss: 0.029366\n",
      "Train Epoch: 2 [89600/180000 (50%)]\tLoss: 0.012252\n",
      "Train Epoch: 2 [102400/180000 (57%)]\tLoss: 0.024685\n",
      "Train Epoch: 2 [115200/180000 (64%)]\tLoss: 0.024985\n",
      "Train Epoch: 2 [128000/180000 (71%)]\tLoss: 0.054731\n",
      "Train Epoch: 2 [140800/180000 (78%)]\tLoss: 0.025114\n",
      "Train Epoch: 2 [153600/180000 (85%)]\tLoss: 0.051278\n",
      "Train Epoch: 2 [166400/180000 (92%)]\tLoss: 0.028502\n",
      "Train Epoch: 2 [179200/180000 (100%)]\tLoss: 0.010673\n",
      "\tLoss: 0.0286(train)\t|\tAcc: 99.6%(train)\n",
      "\tLoss: 0.1889(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9437(valid)\t|\tMacro: 0.9349(valid)\n",
      "Train Epoch: 3 [0/180000 (0%)]\tLoss: 0.041695\n",
      "Train Epoch: 3 [12800/180000 (7%)]\tLoss: 0.013437\n",
      "Train Epoch: 3 [25600/180000 (14%)]\tLoss: 0.010165\n",
      "Train Epoch: 3 [38400/180000 (21%)]\tLoss: 0.027430\n",
      "Train Epoch: 3 [51200/180000 (28%)]\tLoss: 0.015076\n",
      "Train Epoch: 3 [64000/180000 (36%)]\tLoss: 0.042385\n",
      "Train Epoch: 3 [76800/180000 (43%)]\tLoss: 0.023038\n",
      "Train Epoch: 3 [89600/180000 (50%)]\tLoss: 0.009809\n",
      "Train Epoch: 3 [102400/180000 (57%)]\tLoss: 0.020797\n",
      "Train Epoch: 3 [115200/180000 (64%)]\tLoss: 0.019480\n",
      "Train Epoch: 3 [128000/180000 (71%)]\tLoss: 0.041457\n",
      "Train Epoch: 3 [140800/180000 (78%)]\tLoss: 0.021279\n",
      "Train Epoch: 3 [153600/180000 (85%)]\tLoss: 0.041658\n",
      "Train Epoch: 3 [166400/180000 (92%)]\tLoss: 0.022312\n",
      "Train Epoch: 3 [179200/180000 (100%)]\tLoss: 0.009144\n",
      "\tLoss: 0.0238(train)\t|\tAcc: 99.7%(train)\n",
      "\tLoss: 0.1927(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9437(valid)\t|\tMacro: 0.9352(valid)\n",
      "Train Epoch: 4 [0/180000 (0%)]\tLoss: 0.034646\n",
      "Train Epoch: 4 [12800/180000 (7%)]\tLoss: 0.011803\n",
      "Train Epoch: 4 [25600/180000 (14%)]\tLoss: 0.008556\n",
      "Train Epoch: 4 [38400/180000 (21%)]\tLoss: 0.021498\n",
      "Train Epoch: 4 [51200/180000 (28%)]\tLoss: 0.013031\n",
      "Train Epoch: 4 [64000/180000 (36%)]\tLoss: 0.033849\n",
      "Train Epoch: 4 [76800/180000 (43%)]\tLoss: 0.018004\n",
      "Train Epoch: 4 [89600/180000 (50%)]\tLoss: 0.008046\n",
      "Train Epoch: 4 [102400/180000 (57%)]\tLoss: 0.016858\n",
      "Train Epoch: 4 [115200/180000 (64%)]\tLoss: 0.014876\n",
      "Train Epoch: 4 [128000/180000 (71%)]\tLoss: 0.030799\n",
      "Train Epoch: 4 [140800/180000 (78%)]\tLoss: 0.018198\n",
      "Train Epoch: 4 [153600/180000 (85%)]\tLoss: 0.036133\n",
      "Train Epoch: 4 [166400/180000 (92%)]\tLoss: 0.018376\n",
      "Train Epoch: 4 [179200/180000 (100%)]\tLoss: 0.007906\n",
      "\tLoss: 0.0196(train)\t|\tAcc: 99.8%(train)\n",
      "\tLoss: 0.1971(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9439(valid)\t|\tMacro: 0.9356(valid)\n",
      "Now_best:0.9356\n",
      "Train Epoch: 5 [0/180000 (0%)]\tLoss: 0.028000\n",
      "Train Epoch: 5 [12800/180000 (7%)]\tLoss: 0.009625\n",
      "Train Epoch: 5 [25600/180000 (14%)]\tLoss: 0.007068\n",
      "Train Epoch: 5 [38400/180000 (21%)]\tLoss: 0.016805\n",
      "Train Epoch: 5 [51200/180000 (28%)]\tLoss: 0.011279\n",
      "Train Epoch: 5 [64000/180000 (36%)]\tLoss: 0.027126\n",
      "Train Epoch: 5 [76800/180000 (43%)]\tLoss: 0.014176\n",
      "Train Epoch: 5 [89600/180000 (50%)]\tLoss: 0.006591\n",
      "Train Epoch: 5 [102400/180000 (57%)]\tLoss: 0.013970\n",
      "Train Epoch: 5 [115200/180000 (64%)]\tLoss: 0.012015\n",
      "Train Epoch: 5 [128000/180000 (71%)]\tLoss: 0.023008\n",
      "Train Epoch: 5 [140800/180000 (78%)]\tLoss: 0.014629\n",
      "Train Epoch: 5 [153600/180000 (85%)]\tLoss: 0.031359\n",
      "Train Epoch: 5 [166400/180000 (92%)]\tLoss: 0.014247\n",
      "Train Epoch: 5 [179200/180000 (100%)]\tLoss: 0.006471\n",
      "\tLoss: 0.0160(train)\t|\tAcc: 99.8%(train)\n",
      "\tLoss: 0.2023(valid)\t|\tAcc: 94.4%(valid)\n",
      "\tMicro: 0.9437(valid)\t|\tMacro: 0.9354(valid)\n",
      "Train Epoch: 6 [0/180000 (0%)]\tLoss: 0.022543\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88875397f03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 开始训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/nas/workspace/jupyter/code/TextCNN/TrainFunc.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/nas/workspace/jupyter/code/TextCNN/MyDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<UNKNOWN>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# 开始训练\n",
    "mytrain = TrainFunc(model, criterion, opt, loader.train_loader, loader.valid_loader, loader.test_loader)\n",
    "best_model = mytrain.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "68d43d36-e102-434a-b445-8739b5ce36db"
   },
   "outputs": [],
   "source": [
    "ans=mytrain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "uuid": "fe45e37a-92ec-42f1-bfcf-f67a3413ea32"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_sub=pd.read_csv(data_root[\"sub_path\"])\n",
    "df_sub.label=np.array(ans)\n",
    "df_sub.label=df_sub.label.astype(\"int64\")\n",
    "save_name=\"./textcnn_{:.4f}.csv\".format(mytrain.best_score)\n",
    "df_sub.to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "uuid": "87ad82b6-b378-4711-9721-2b67be890b06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9355598130314265"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "57ecb89f-4212-42df-895a-7b9434ad1f43"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
